{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy0Y6xTLNtM6"
   },
   "source": [
    "# Introductie Deep Learning\n",
    "\n",
    "Auteurs: Joost Vanstreels (joost.vanstreels@hu.nl), Tijmen Muller (tijmen.muller@hu.nl) en Peter van den Berg (peter.vandenberg@hu.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cro1QI9NtM7"
   },
   "source": [
    "In semester 4 van de opleiding _Artificial Intelligence_ staat het onderwerp _Deep Learning_ centraal. Bij _Deep Learning_ worden neurale netwerken gebruikt om patronen te herkennen in allerlei ongestructureerde data, zoals beeld, video, audio en tekst. In deze introductie gaan we meteen wat basisstappen doorlopen om een simpel neuraal netwerk te maken. We doen dit met behulp van het populaire framework PyTorch (https://pytorch.org/), dat we vaker zullen gebruiken in het semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgLiUhUr4t4d"
   },
   "source": [
    "## Inleiding\n",
    "\n",
    "### Doel\n",
    "\n",
    "Het doel van dit notebook is om een beeld te krijgen van de werking van neurale netwerken:\n",
    "\n",
    "- Wat zijn neurale netwerken en hoe werken ze?\n",
    "- Welke type problemen kun je oplossen met neurale netwerken?\n",
    "- Wat is het verschil met andere machine learning technieken die zijn behandeld in S3, zoals decision trees en k-nearest neighbours?\n",
    "- Wat is de toegevoegde waarde van _convolutionele_ neurale netwerken (CNNs)?\n",
    "\n",
    "### Opzet\n",
    "\n",
    "Aan de hand van theoretische uitleg en praktische voorbeelden gaan jullie zelfstandig aan de slag met enkele opdrachten:\n",
    "\n",
    "1. We starten met het opzetten van een simpel neuraal netwerk dat jullie gaan aanpassen om betere resultaten te krijgen;\n",
    "2. Daarna gaan jullie het neuraal netwerk uitbreiden met meerdere lagen;\n",
    "3. Ook dit model gaan jullie verbeteren, op zoek naar een hoge nauwkeurigheid;\n",
    "4. Tenslotte gaan we hetzelfde proberen te realiseren met k-NN.\n",
    "\n",
    "### Voorbereiding\n",
    "\n",
    "- Installeer de benodigde libraries (zie [`README.md`](./README.md)) en draai het notebook bij voorkeur lokaal. Mocht je het niet werkend krijgen, dan kun je uitwijken naar Google Colab.\n",
    "\n",
    "### Werkwijze\n",
    "\n",
    "- Lees de uitleg goed;\n",
    "- Voer de code stap-voor-stap uit;\n",
    "- Voer de opdrachten uit; cellen die getagd zijn met `student` moet je zelf invullen;\n",
    "- Voor het uitvoeren van de opdrachten heb je geen externe bronnen nodig: alle benodigde kennis is gegeven in dit notebook;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpfctwLyNtM7"
   },
   "source": [
    "## Deel I. Machine learning met neurale netwerken\n",
    "\n",
    "### Herkennen van handgeschreven cijfers\n",
    "\n",
    "We gaan aan de slag met de '*Hello, World!*' van neurale netwerken: het herkennen van de handgeschreven cijfers van de [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Deze dataset bestaat uit een trainset van 60.000 plaatjes met cijfers en een testset van nog eens 10.000 plaatjes.\n",
    "\n",
    "De plaatjes zien er als volgt uit (bron: https://commons.wikimedia.org/wiki/File:MnistExamples.png):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A few samples from the MNIST test dataset.](./img/MnistExamples.png \"A few samples from the MNIST test dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjDwn6ArNtM7"
   },
   "source": [
    "### Benodigde libraries \n",
    "\n",
    "We hebben een aantal libraries nodig, sommigen kennen jullie al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QfscTgLkNtM8"
   },
   "outputs": [],
   "source": [
    "import random  \n",
    "import time\n",
    "import platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchmetrics.classification\n",
    "import torchinfo\n",
    "\n",
    "# Wetenschappelijke notitie uitzetten voor leesbaarheid\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getest met: Python 3.12.12 en PyTorch 2.9.1+cu128\n",
      "Huidige installatie: Python 3.12.12 en PyTorch 2.9.1+cu128\n",
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "source": [
    "# Controleer versie\n",
    "print(\"Getest met: Python 3.12.12 en PyTorch 2.9.1+cu128\")\n",
    "print(\"Huidige installatie: Python\", platform.python_version(), \"en PyTorch\", torch.__version__)\n",
    "\n",
    "# Controleer en selecteer device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')  # Forceer cpu\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QljqpqwxNtM8"
   },
   "source": [
    "### Stap 1. Data exploration & data transformation\n",
    "\n",
    "De MNIST dataset is gebundeld in PyTorch, we kunnen deze eenvoudig importeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.39MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 342kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.27MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x23C331E9640>, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_original = datasets.MNIST(root='data/', train=True, download=True)\n",
    "print(dataset_original[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we kijken naar de inhoud van de dataset, dan zien we dat één datapunt bestaat uit een afbeelding in [PIL-formaat](https://pillow.readthedocs.io/en/stable/) op index 0 en een integer op index 1. Er zijn 60.000 datapunten in de trainset en 10.000 datapunten in de testset.\n",
    "\n",
    "De integer is de klasse van het datapunt, dus welk getal het plaatje voorstelt: in geval van het eerste datapunt dus een '5'. De inhoud van de afbeelding kunnen we eenvoudig weergeven met PyPlot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(dataset_original[0][0], cmap='binary', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een neuraal netwerk kan niet omgaan met deze ruwe data, maar heeft _matrices van getallen_ nodig als input. Gelukkig heeft PyTorch functionaliteit beschikbaar om deze conversie voor ons te doen in de vorm van [`ToTensor()`](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor). Deze zet de afbeelding om in een Numpy array met de dimensies _kleurkanaal_ x _hoogte_ x _breedte_. We kunnen deze functie direct meegeven bij het importeren van de dataset, dus dat doen we hier opnieuw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 60000 items\n",
      "Test set: 10000 items\n"
     ]
    }
   ],
   "source": [
    "dataset_train = datasets.MNIST(root='data/', train=True, download=True, transform=ToTensor())\n",
    "dataset_test = datasets.MNIST(root='data/', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "print(\"Train set:\", len(dataset_train), \"items\")\n",
    "print(\"Test set:\", len(dataset_test), \"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien nu dat de afbeelding op index 0 is vervangen door een tensor van 1 x 28 x 28. Het gaat dus om een plaatje van 28 bij 28 pixels, met in de eerste dimensie een kleurkanaal. Omdat we te maken hebben met grijstinten, is er hier maar sprake van één dimensie -- die kunnen we verwijderen zonder verlies van informatie. In het geval van een afbeelding met kleur zouden we drie (RGB) dimensies hebben op dit kanaal, dat zouden we niet zomaar mogen verwijderen!\n",
    "\n",
    "Als we naar het datatype kijken, dan zien we dat het gaat om een `torch.Tensor`. Voor nu is het voldoende om te weten dat zo'n Tensor veel lijkt op een Numpy array, maar dat een tensor extra functionaliteit geeft die in het bijzonder belangrijk is voor _deep learning_.\n",
    "\n",
    "**NB**. Als je kijkt naar de dataset dan zie je een groot verschil met de datasets die we gezien hebben bij het vorige semester, _Data Science_. Daar hadden we te maken met `.csv`-bestanden met datasets met meerdere kolommen en verschillende datatypes als inhoud. We konden kiezen welke features we als input gingen gebruiken. Met andere woorden: de inhoud van deze datasets was gestructureerd (als een tabel). De MNIST train dataset bestaat eigenlijk uit 60.000 keer 784 (28 x 28) pixelwaardes... dat is ongestructureerde data. Want er is dataschema over de betekenis van  pixels op een bepaalde rij of kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_train[0][0].shape, end='\\n\\n')\n",
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan de datasets omvormen tot een train en een test set met daarin de plaatjes en de klassen apart. We verwijderen daarbij direct het ééndimensionale kleurkanaal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.zeros(size=(60000, 28, 28))\n",
    "y_train = torch.zeros(size=(60000, 1))\n",
    "\n",
    "for i, data in enumerate(dataset_train):\n",
    "    # Verwijder kleurkanaal\n",
    "    x_train[i] = data[0].reshape(28,28) \n",
    "    y_train[i] = data[1]\n",
    "    \n",
    "x_test = torch.zeros(size=(10000, 28, 28))\n",
    "y_test = torch.zeros(size=(10000, 1))\n",
    "\n",
    "for i, data in enumerate(dataset_test):\n",
    "    # Verwijder kleurkanaal\n",
    "    x_test[i] = data[0].reshape(28,28) \n",
    "    y_test[i] = data[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_qbg_vsNtM9"
   },
   "source": [
    "Met matplotlib kunnen we weer een aantal plaatjes uit de dataset bekijken, ook nu het matrices van getallen zijn geworden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "ivZmzp_MNtM9",
    "outputId": "bdd324cc-ddb1-4f79-815a-3c8b1ecb50f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    mnist_number = random.randint(0, len(dataset_train))\n",
    "    plt.imshow(x_train[mnist_number], cmap='binary', interpolation='none')\n",
    "    plt.title(f\"#{mnist_number}\\nklasse {int(y_train[mnist_number][0])}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ieu_YyFSNtM9"
   },
   "source": [
    "Een plaatje is nu dus eigenlijk niks meer dan een tweedimensionale array met 28 x 28 grijswaardes. Elke pixel is een float met waardes tussen 0 (zwart) en 1 (wit). Hieronder wordt complete matrix getoond van het getal rechtsonder in bovenstaande figuur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVUbivD8NtM9",
    "outputId": "762f7395-f951-49df-e35a-a1345f65c04d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0  0.29  0.41   0.41   0.41   0.75     1   0.99   0.99  0.99   0.7     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0  0.38  0.94  0.99   0.99   0.99   0.99  0.99   0.99   0.99  0.99  0.94  0.24  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0  0.87  0.99  0.99   0.99   0.99   0.99  0.99   0.99   0.98  0.93  0.75   0.1  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0   0.6  0.99  0.99   0.99   0.99   0.99  0.52   0.52   0.49     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0  0.21   0.9  0.99   0.99   0.99   0.47     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0  0.27  0.93   0.99   0.99   0.82     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0  0.25   0.96   0.99   0.99  0.53  0.094      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0   0.38   0.99   0.99  0.99   0.17      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0  0.082   0.71   0.99  0.99   0.66  0.063     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0  0.075   0.75  0.99   0.99   0.35     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0   0.58     1   0.99   0.93     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0    0.1  0.85   0.99   0.98  0.43     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0  0.41   0.99   0.99  0.52     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0  0.41   0.99   0.99  0.52     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0  0.58   0.99   0.99  0.52     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0  0.071  0.99   0.99   0.99  0.52     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0  0.094    0.8  0.99   0.99   0.96  0.25     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0  0.19   0.35   0.81   0.99  0.99   0.76  0.051     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0  0.23  0.76  0.88   0.99   0.99   0.99  0.82   0.27      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0  0.29  0.99  0.99   0.99   0.88    0.4     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  0     0     0     0      0      0      0     0      0      0     0     0     0  0  0  0  0  0  0  0  \n"
     ]
    }
   ],
   "source": [
    "def matprint(mat, fmt=\".2g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print()\n",
    "\n",
    "matprint(x_train[mnist_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5E9Y2SMNtM-"
   },
   "source": [
    "### Stap 2. Data preparation\n",
    "\n",
    "#### Features\n",
    "\n",
    "De input voor het neuraal netwerk is de matrix die het plaatje representeert. Dat plaatje bestaat eigenlijk uit 784 features, namelijk alle 784 pixels. Zo'n 28 x 28 matrix is niet handig als input voor een 'gewoon' neuraal netwerk. We moeten er een vector van maken door _flattening_ toe te passen (zie figuur hieronder). We vormen de 28 x 28 matrix dan om tot een vector met een lengte van 28 x 28 = 784 elementen.\n",
    "\n",
    "NB. Het is ook belangrijk om de input te normaliseren. Dat is hier niet meer nodig, omdat de grijswaarden allemaal al netjes tussen 0 en 1 liggen door de eerder toegepaste transformatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmvZVFR2NtM-"
   },
   "source": [
    "![Flattening](./img/flattening.png \"Flattening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PWzi6ilNtM-",
    "outputId": "5213e0a0-ea89-4c87-8a5e-f49c87f85ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: torch.Size([60000, 784])\n",
      "Testing matrix shape: torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "# Let op: we schakelen hier over van een kleine letter naar een hoofdletter, zodat de originele\n",
    "# trainingsdata in `x_train` beschikbaar blijft!\n",
    "\n",
    "# Reshape de 60.000 plaatjes van 28 x 28 matrices naar 60.000 784-lengte vectoren.\n",
    "X_train = x_train.reshape(60000, 784)  \n",
    "X_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(\"Training matrix shape:\", X_train.shape)\n",
    "print(\"Testing matrix shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBfvAPyKNtM-"
   },
   "source": [
    "#### Target\n",
    "\n",
    "De target variabele is een 0, 1, 2, ... of 9. Dat zijn de verschillende klasses of categorieën. Kijk bijvoorbeeld maar eens naar de inhoud van een willekeurig item uit `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rD1M2Ehy4t4k",
    "outputId": "03ed6a0e-529b-4803-8505-deb26c1bfd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dit is een: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABGFJREFUeJzt3c8rdG0cgPEzUrIYLCU7W+YPUMqGjR8rYWshJSlZ+FGzkpU9FrKzsJUoOyUbm2mKnYWmJELZ2Kjz9vQu73vqeIfHeznXZ/ntfmZO09Vd9zHPmUKapmkiwTT99AVI/4XhCslwhWS4QjJcIRmukAxXSIYrJMMVkuEKyXCFZLhCMlwhGa6QDFdIhiskwxWS4QrJcIVkuEIyXCEZrpAMV0iGKyTDFZLhCslwhWS4QjJcIRmukAxXSIYrJMMVkuEKyXCFZLhCMlwhGa6QDFdIhiskwxWS4Qqp+acv4P/g+Pg4mNVqtYZf9/DwMJidn59H1xYKhYbea3R0NDo/OjpKfiN3XCEZrpAMV0iGK6RCmqZpkhP7+/vR+fLycjB7e3v7lmuo93E3ejhra2vLfDgbGBhI6NxxhWS4QjJcIRmukAxXSLn6k+/GxkZ0/l13EBrV1BTfV4rFYjArlUrRtT09Pclv5I4rJMMVkuEKyXCFlKvD2fDwcHS+t7f3165hdXU180GspaUlurZcLid5544rJMMVkuEKyXCFZLhCytUXya+urqLz8fHxYPb4+Njw+21ubma+q6DPcccVkuEKyXCFZLhCytXhrJ6zs7NgNjU11fB3d/v6+oJZpVL55NUpxh1XSIYrJMMVkuEKyXCF5F2FOuo9gHlkZCSYvb+/Z37dlZWV6HxxcTGYdXZ2Zn7dvHHHFZLhCslwhWS4QvJw9gUPh56dnc387+t93NVqNZj19vZ+8urywx1XSIYrJMMVkuEKyXCF5F2FT3p6egpmMzMz0bWnp6fBrN7HPTk5Gcx2d3ejazs6OpK8c8cVkuEKyXCFZLhC8nD2BZ6fn6PziYmJzN/zjf2W78HBQXTt9PR0knfuuEIyXCEZrpAMV0iGKyTvKnyj+fn5YLazs5P5rkJ7e3t07evra5J37rhCMlwhGa6QDFdIHs6+0f39fTAbHByMrr29vQ1mzc3xn1re2trK9Ain38wdV0iGKyTDFZLhCslwhRQ/tupLdHV1BbOlpaXo2oWFhWD28fERXfv4Bb8zTOeOKyTDFZLhCslwhWS4QjJcIRmukAxXSIYrJMMVkn/y/cuur69/+hJ+BXdcIRmukAxXSIYrJA9n3+jl5SWYbW9vZ34Ek+pzxxWS4QrJcIVkuEIyXCF5V+ELPDw8ROdjY2MNvW5ra2t0PjQ0lOSdO66QDFdIhiskwxWSh7M6KpVKdH5zc5PpQct/VKvVzO/X398fzE5OTqJri8ViknfuuEIyXCEZrpAMV0iGK6Rc3VW4vLyMztfW1oLZ3d1ddG2tVmvoGkqlUnReLpeDmXcP6nPHFZLhCslwhWS4QmrO+/+6/ePi4qKh1+3u7o7O19fXg9nc3FxD76V/ueMKyXCFZLhCMlwhGa6QCmmapj99EdJnueMKyXCFZLhCMlwhGa6QDFdIhiskwxWS4QrJcIVkuEIyXCEZrpAMV0iGKyTDFZLhCslwhWS4QjJcJUT/AOnuy8UPm9urAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dit is een:\", int(y_train[mnist_number]))\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[mnist_number].reshape(28,28), cmap='binary', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2WphOHCPWrI"
   },
   "source": [
    "In het vorige Data Science semester hebben we altijd gewerkt met één targetvariabele die meerdere waardes kon krijgen. Denk aan classificeren waarbij je verschillende klasses kon voorspellen of regressie waarbij je meerdere waardes kon voorspellen.\n",
    "\n",
    "In dit geval werkt het iets anders: we hebben meerdere targetvariabelen die allemaal corresponderen met één klasse. In dit geval hebben we 10 target variabelen die corresponderen met 0, 1, 2, ... of 9. \n",
    "\n",
    "We moeten de target aanpassen naar het onderstaande formaat. Deze transformatie noemen we _one hot encoding_.\n",
    "\n",
    "- `0` wordt `[1, 0, 0, 0, 0, 0, 0, 0, 0`]\n",
    "- `1` wordt `[0, 1, 0, 0, 0, 0, 0, 0, 0`]\n",
    "- `2` wordt `[0, 0, 1, 0, 0, 0, 0, 0, 0]`\n",
    "- et cetera\n",
    "\n",
    "Het neuraal netwerk gaat straks proberen te voorspellen welk cijfer in een plaatje staat. Net zoals bij decision trees, k-NN, etc. zal een voorspelling niet altijd 100% zeker zijn. Het zal vaak een voorspelling zijn met een bepaalde betrouwbaarheid, bijvoorbeeld iets als dit:\n",
    "\n",
    "`[0.94, 0, 0, 0, 0, 0, 0.06, 0, 0.07, 0.11]`\n",
    "\n",
    "In dit geval is de voorspelling een '0' met een hoge zekerheid (want de waarde 0.94 op index `0` geeft een hoge kans), maar geeft het neurale netwerk ook een kleine kans aan een '6', een '8' en een '9'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qbgh99vpNtM_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De tensor([5.]) is na one hot encoding: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10  # Aantal klassen\n",
    "\n",
    "Y_train = one_hot(y_train.long(), n_classes).squeeze().float()\n",
    "Y_test = one_hot(y_test.long(), n_classes).squeeze().float()\n",
    "\n",
    "print(\"De\", y_train[mnist_number], \"is na one hot encoding:\", Y_train[mnist_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen deze _one hot encoding_ weer eenvoudig terugvertalen naar het originele label (en dus het getal dat het plaatje voorstelt) met behulp van de `argmax()` functie. Deze functie geeft de _index_ terug van het maximum in een array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]) heeft het maximum op index 5\n",
      "\n",
      "Voorspelling tensor([0.9400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0600, 0.0000, 0.0700,\n",
      "        0.1100]) heeft het maximum op index 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding\", Y_train[mnist_number], \"heeft het maximum op index\", int(torch.argmax(Y_train[mnist_number])))\n",
    "\n",
    "pred = torch.Tensor([0.94, 0, 0, 0, 0, 0, 0.06, 0, 0.07, 0.11])\n",
    "print(\"\\nVoorspelling\", pred, \"heeft het maximum op index\", int(torch.argmax(pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z7yyUUpNtM_"
   },
   "source": [
    "### Stap 3. Modelling\n",
    "\n",
    "#### Een eerste supersimpel netwerk\n",
    "We gaan toewerken naar een _fully connected network_ met 3 _layers_ (lagen) plus een inputlaag zoals hieronder. Merk op dat je dit figuur van onder naar boven moet lezen: de input (het plaatje van 28 bij 28) staat onderaan, de output (met andere woorden, de voorspelde klasse) staat bovenaan.\n",
    "\n",
    "![Compleet netwerk](./img/network_complex.png \"Compleet netwerk\")\n",
    "\n",
    "Maar voordat we dat gaan doen, gaan we eerst een heel simpel netwerk maken dat maar uit één laag bestaat. De input voor het netwerk zijn de 784 pixels en de output zijn de 10 mogelijke klasses:\n",
    "\n",
    "![Simpel netwerk](./img/network_simple.png \"Simple netwerk\")\n",
    "\n",
    "#### Hoe werkt een neuraal netwerk?\n",
    "\n",
    "Een voorspelling van een neuraal netwerk bestaat eigenlijk uit weinig meer dan heel veel berekeningen; dit noemen we de _feed forward_. Een netwerk bestaat uit *neuronen* en *verbindingen*. Voor alle 784 pixels zijn neuronen gemaakt die zijn gekoppeld aan alle 10 klassen in de outputlaag; ook hiervoor zijn neuronen gemaakt. Er zijn in totaal 784 x 10 = 7.840 verbindingen tussen alle neuronen van de inputlaag en de neuronen van de outputlaag. Daarbovenop zijn er nog 10 verbindingen met 10 biasneuronen.\n",
    "\n",
    "Elke verbinding heeft een gewicht. De waarde van elke pixel is de waarde van de inputneuron, deze wordt vermenigvuldigd met het gewicht van een verbinding. Elk van de 10 outputneuronen heeft als input de som van alle vermenigvuldigingen. De klasse van de outputneuron waarvan de som het hoogste is, is de voorspelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LIqyfoI4t4l"
   },
   "source": [
    "#### Model opbouwen\n",
    "\n",
    "Om een neuraal netwerk te definiëren in PyTorch, moeten we een klasse maken op basis van de `nn.Module` klasse:\n",
    "- In de `__init__()` constructor definiëren we de lagen van ons netwerk; in het geval van ons simpele netwerk is dat één laag. Het type laag dat we hier gebruiken is `Linear`.\n",
    "- In de `forward()` methode definiëren we _hoe_ de input data `x` stapsgewijs door de lagen gaat. In ons geval gaat het simpelweg door de ene laag; de uitvoer van deze laag `logits` heeft dus 10 elementen na de berekening die plaatsvindt in onze enige laag `fc1`.\n",
    "- Tenslotte kiezen we een activatiefunctie, die een (niet-lineaire) berekening doet op de uitvoer van een laag. Het type activatiefunctie is hier `Sigmoid()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R8sKxKh4t4m"
   },
   "source": [
    "_Activatiefunties_ zijn berekeningen om iets slims te doen met de som van alle vermenigvuldigingen die als input binnen komen. Later zullen we zien waarom dat zo belangrijk is. In dit geval nemen we de _sigmoid function_ als activatiefunctie. Deze zorgt ervoor dat de output nooit lager dan -1 of hoger dan 1 wordt. Dit is een soort van normaliseren. Voor de volledigheid, de formule en de grafiek van de sigmoid zijn:\n",
    "\n",
    "$$ a(z) = \\frac{1}{1 + {\\rm e}^{-Z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvGFbxB5NtNA"
   },
   "source": [
    "![Sigmoid](./img/sigmoid_function.png \"Sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opdracht**: kies het juiste aantal inputs `n_inputs` en outputs `n_outputs` voor de laag `fc1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(n_inputs, n_outputs)\n",
    "    self.fn_activate = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Pass data x door eerste laag\n",
    "    logits = self.fc1(x)\n",
    "\n",
    "    # Activatie met sigmoid\n",
    "    a = self.fn_activate(logits)\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def reset(self):\n",
    "    # Reset gewichten van het network\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQDotXbcNtM_"
   },
   "source": [
    "We initialiseren tenslotte het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m simple_model = \u001b[43mSimpleNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m simple_model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mSimpleNetwork.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m      3\u001b[39m   \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m   \u001b[38;5;28mself\u001b[39m.fc1 = nn.Linear(\u001b[43mn_inputs\u001b[49m, n_outputs)\n\u001b[32m      5\u001b[39m   \u001b[38;5;28mself\u001b[39m.fn_activate = nn.Sigmoid()\n",
      "\u001b[31mNameError\u001b[39m: name 'n_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "simple_model = SimpleNetwork()\n",
    "simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhVRDLgO4t4o"
   },
   "source": [
    "Ons eerste, simpele model is nu helemaal opgebouwd. Met `torchinfo.summary()` kunnen we een samenvatting van het eindresultaat krijgen. Hieronder zie je het volgende, als je alles goed hebt gedaan:\n",
    "\n",
    "```raw\n",
    "=================================================================\n",
    "Layer (type:depth-idx)                   Param #\n",
    "=================================================================\n",
    "SimpleNetwork                            --\n",
    "├─Linear: 1-1                            7,850\n",
    "├─Sigmoid: 1-2                           --\n",
    "=================================================================\n",
    "Total params: 7,850\n",
    "Trainable params: 7,850\n",
    "Non-trainable params: 0\n",
    "=================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchinfo.summary(simple_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluatie (prelude)\n",
    "\n",
    "Ons eerste supersimpele model is nu al gereed om te voorspellen, maar het is nog _niet_ getraind. Het model is geinitialiseerd met willekeurige waarden als parameters, dus we kunnen het gebruiken om te voorspellen, maar het zal zeer slecht presteren, want in feite gokt het maar wat. Hieronder een voorbeeld van een voorspelling (eigenlijk een gok dus) en de echte waarde. (Als ze overeenkomen, is dit puur toeval.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = simple_model(X_train[mnist_number])\n",
    "\n",
    "print(\"De voorspelling per cijfer:\", prediction)\n",
    "print(\"Dit komt overeen met het voorspelde label:\", torch.argmax(prediction))\n",
    "\n",
    "print(\"\\nDe echte waarde is:\", Y_train[mnist_number])\n",
    "print(\"Dit komt overeen met het echte label:\", torch.argmax(Y_train[mnist_number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Door bovenstaande vergelijking tussen voorspelling en echte waarde uit te voeren op _alle_ waarden uit een dataset kunnen we een accuracy berekenen: welk deel van de (in dit geval train) dataset wordt goed voorspeld door het model? Nogmaals: we werken met willekeurige waarden, dus het resultaat moet een heel laag percentage zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor het bepalen van de accuracy maken we gebruik van `torchmetrics`, die alle gebruikelijke evaluatiemetrieken voor ons kan bepalen. Laten we hier een functie `evaluate()` voor schrijven, die komt later vast nog van pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, inputs, targets, device='cpu'):\n",
    "    # print(f\"Evaluating model on {device}\")\n",
    "    \n",
    "    # Data op juiste device plaatsen\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    # Voorspel voor gehele dataset\n",
    "    predictions = model(inputs)\n",
    "\n",
    "    # Decodeer voorspellingen en targets\n",
    "    predicted_labels = torch.argmax(predictions, dim=1)\n",
    "    targets = torch.argmax(targets, dim=1)\n",
    "\n",
    "    # Initialiseer accuracy berekening op voorspellingen en targets\n",
    "    test_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=n_classes).to(device)\n",
    "    test_accuracy.update(predicted_labels, targets)\n",
    "\n",
    "    return test_accuracy.compute().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opdracht**: Beredeneer welke _accuracy_ je hier verwacht; met andere woorden: wat is de prestatie van je baseline model en waarom?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "_Schrijf hier je antwoord._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate(simple_model, X_train, Y_train)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udLdi_-QNtND"
   },
   "source": [
    "### Training configureren\n",
    "\n",
    "In semester 3 hebben we gezien dat een model allerlei hyperparameters kent, zoals de diepte van een beslisboom, de afstandsfunctie bij _k_-NN of het aantal clusters bij _k_-Means. Er zijn ook veel hyperparameters te kiezen bij het trainen van machine learning modellen, maar daar hebben we nog maar weinig aandacht aan geschonken in S3. De belangrijkste reden hiervoor is dat het optimalisatie-algoritme niet zo belangrijk is bij de modellen die we in S3 gebruikt hebben. Het trainen (of 'fitten') van het model met het standaardalgoritme lukte altijd goed en snel genoeg.\n",
    "\n",
    "Bij neurale netwerken werkt het trainen van een model anders. Het is een stuk complexer waardoor er twee risico's zijn:\n",
    "- Je vindt geen goede oplossing;\n",
    "- Het vinden van een goede oplossing duurt lang.\n",
    "\n",
    "Daarom moet je bij een neuraal netwerk goed nadenken over de **loss function** en de **optimizer** bij het trainen met behulp van **gradient descent**. Daarbij is ook de **learning rate** erg belangrijk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpESZz2yNtNE"
   },
   "source": [
    "#### Gradient descent\n",
    "\n",
    "Gradient descent is het zoeken naar een minimum:\n",
    "\n",
    "![Gradient descent](./img/gd.png \"Gradient descent\")\n",
    "\n",
    "Je kunt dat minimum niet zien, dus je moet stapjes in de juiste richting nemen. De grootte van een stap is de learning rate. Kleine stapjes nemen duurt lang, maar te grote stappen is ook niet altijd goed:\n",
    "\n",
    "![Effect of learning rates](./img/lr_effect.png \"Effect of learning rates\")\n",
    "\n",
    "Kleine stapjes zijn niet altijd beter. Het risico bij kleine stapjes is dat je blijft hangen bij een lokaal minimum, terwijl er andere (lagere) minima bestaan. Het vinden van het globale minimum is de optimale situatie.\n",
    "\n",
    "![Global and local minima](./img/local_minimum.png \"Global and local minima\")\n",
    "\n",
    "Enfin, hier gaan we later mee aan de slag. Voor nu kiezen we de volgende configuraties voor de _loss functie_ en de _optimizer_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=simple_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U72jBYYo4t4q"
   },
   "source": [
    "### Het model trainen\n",
    "\n",
    "Nu kunnen we eindelijk het model gaan trainen! Zoals gezegd, werkt dat anders dan bij de modellen uit semester 3. De gewichten van alle verbindingen moeten berekend worden. Dat doe je stap-voor-stap:\n",
    "\n",
    "- Voor elk item uit de traindata:\n",
    "  1. Bepaal de output van het neurale netwerk.\n",
    "  2. Vergelijk de output met de echte waarde.\n",
    "  3. Als de waarde goed is, ga je naar het volgende item.\n",
    "  4. Als de waarde niet goed is, dan pas je de gewichten van de verbindingen aan die tot het verkeerde antwoord geleid hebben.\n",
    "\n",
    "Dat zijn heel veel berekeningen... en dat kost dus ook heel veel tijd! Je gaat daarom bij neurale netwerken niet op zoek naar dé oplossing (als die al bestaat...), maar naar _een_ oplossing die goed genoeg is. Of naar de beste oplossing gegeven een bepaalde tijd (_runtime_).\n",
    "\n",
    "Hieronder een functie voor de training loop voor één _epoch_, waarbij alle datapunten één keer worden meegenomen in het trainen van het netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, data_loader, optimizer, criterion, device='cpu'):\n",
    "    \"\"\" Train network for one epoch. \"\"\"\n",
    "    train_loss = 0.\n",
    "\n",
    "    # Loop over alle batches van de dataset\n",
    "    for i_batch, (inputs, target) in enumerate(data_loader):\n",
    "        # Zet het model in trainmodus\n",
    "        network.train()\n",
    "\n",
    "        # Elke data-instantie is een (input, label) paar\n",
    "        # Naar juiste device verplaatsen\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        # maak voorspellingen voor deze batch\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Bereken de loss en de gradients\n",
    "        loss = criterion(outputs, target)\n",
    "        train_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        # Bereken gradient\n",
    "        loss.backward()\n",
    "        # Pas gewichten aan\n",
    "        optimizer.step()\n",
    "        # Zet gradients terug naar 0 voor volgende iteratie\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Bereken de loss per epoch en return\n",
    "    epoch_loss = train_loss / len(data_loader)\n",
    "    return epoch_loss.cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Een epoch trainen\n",
    "\n",
    "We kunnen het netwerk nu een epoch gaan trainen! Hiertoe maken we een `DataLoader` object, die onze data in _batches_ kan inladen. Een _batch_ is hierbij een 'pakketje' met datapunten, waarbij je de grootte (dus het aantal datapunten) kan instellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de methode `to()` kunnen we het model naar een _device_ verplaatsen; dat is CUDA als je een geschikte GPU hebt en anders gewoon de CPU.\n",
    "\n",
    "NB. De variabele `device` is helemaal aan het begin van dit notebook eenmalig geinitialiseerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = simple_model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we de functie `train()` nu één keer uitvoeren, dan krijgen we de _loss_ terug op de training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = train(simple_model, training_loader, optimizer, loss_fn, device)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de functie die we eerder hebben geschreven, kunnen we ook de accuracy bepalen op de train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate(simple_model, X_train, Y_train, device=device)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj3-sTMGNtNH"
   },
   "source": [
    "Je ziet de **loss** en **accuracy**. De accuracy kennen jullie: dat is het percentage goed voorspelde cijfers. De loss is het resultaat van de _loss function_ (ook wel _cost function_ genaamd). Het is nog te vroeg om hier dieper op in te gaan, maar onthoud voor nu dat het een foutmaat is, dus we willen hier een zo klein mogelijk getal zien: in de perfecte wereld is de loss gelijk aan 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT4Cx2u7NtNH"
   },
   "source": [
    "### Stap 4. Evalueren\n",
    "\n",
    "Leuk, die accuracy op de traindata, maar veel belangrijker is natuurlijk de prestatie op de test data! We kijken weer naar de accuracy, maar ook naar de loss (alhoewel die minder interessant is op dit moment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = simple_model(X_test.to(device)).to('cpu')\n",
    "loss = loss_fn(predictions_test, Y_test)\n",
    "\n",
    "accuracy = evaluate(simple_model, X_test, Y_test, device=device)\n",
    "\n",
    "print(f\"Results on test set: loss = {loss:.4f}, accuracy = {accuracy*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGUy0tt6NtNI"
   },
   "source": [
    "De algemene evaluatie is belangrijk, maar het is ook goed om specifieke / individuele voorspellingen te bekijken. Hieronder zie je een visualisatie van correct en incorrect voorspelde cijfers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = torch.argmax(simple_model(X_test.to(device)), dim=1)\n",
    "predicted_classes = predicted_classes.to('cpu')\n",
    "correct = (predicted_classes == y_test.squeeze())\n",
    "\n",
    "correct_indices = torch.nonzero(predicted_classes == y_test.squeeze())\n",
    "incorrect_indices = torch.nonzero(predicted_classes != y_test.squeeze())\n",
    "\n",
    "print(f\"{len(correct_indices)} correct voorspeld\")\n",
    "print(f\"{len(incorrect_indices)} incorrect voorspeld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_DV1atVNtNJ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[correct].reshape(28,28), cmap='binary', interpolation='none')\n",
    "    plt.title(f\"Predicted {int(predicted_classes[correct])}\\n Class {int(y_test[correct])}\")\n",
    "    plt.axis('off')   \n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i, correct in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='binary', interpolation='none')\n",
    "    plt.title(f\"Predicted {int(predicted_classes[correct])}\\n Class {int(y_test[correct])}\")\n",
    "    plt.axis('off')   \n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpuNWyPp4t4s"
   },
   "source": [
    "### Opdracht 1. De accuracy verhogen\n",
    "\n",
    "Een manier om te spelen met het trainen, is de keuze voor een **batch size**. Dit bepaalt hoeveel items uit de dataset per stap bekeken worden, voordat de gewichten geüpdatet worden. Grotere batch sizes zorgen voor nauwkeuriger trainen, de updates van de parameters zijn dan erg precies. Een kleine batch size (waarbij _online learning_ met batch size gelijk aan 1 de kleinste optie is) zorgt voor snelle updates (na elke batch een update), maar is minder nauwkeurig qua richting. Ook complexiteit speelt een rol bij het kiezen van batch size: een grotere batch gebruikt meer geheugen, maar is computationeel sneller. In de praktijk blijkt een grote batch size de neiging tot overfitting te hebben, maar de oorzaak hiervan is niet helemaal duidelijk. Het zoeken naar de beste batch size is vaak een kwestie van trial en error. Een goed startpunt is een batch size tussen de 32 en de 512 datapunten.\n",
    "\n",
    "Daarnaast is het aantal **epochs** ook belangrijk. Dit geeft aan hoe vaak je de hele training set wilt gebruiken. Het is niet zo dat je na het bekijken van alle items uit de trainset klaar bent, je kunt de trainset nog een keer gebruiken om het model te verbeteren. En nog een keer. Enzovoorts. Zie het als het studeren voor een tentamen waarbij je een oefententamen vaker maakte om de stof te begrijpen.\n",
    "\n",
    "**Opdracht.** Gebruik de code van een paar stappen terug en kijk of je de accuracy kunt verhogen. Dat kan op verschillende manieren.  \n",
    "Kijk ook naar de benodigde tijd: duurt het trainen langer of korter?\n",
    "\n",
    "Speel met:\n",
    "- epochs\n",
    "- batch size\n",
    "\n",
    "**Merk op**: wanneer je meerdere keren achter elkaar de `train()` functie aanroept, train je het model steeds _verder_. Het is dus handig om na elk experiment het model te resetten om een eerlijke vergelijking te krijgen. Je kan hiervoor de `reset()` methode gebruiken: die overschrijft alle gewichten met willekeurig gekozen waarden en maakt het model dus effectief weer 'ongetraind'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ8--sKH4t4t"
   },
   "source": [
    "Geef hieronder aan welke accuracy je hebt behaald bij welk aantal epochs en welke batch size. Als je in de buurt bent van 92% accuracy op de testset, dan kun je door naar de volgende opdracht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "_Schrijf hier je antwoord._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1UNAal64t4t"
   },
   "source": [
    "### Opdracht 2. Modelling van een completer netwerk\n",
    "\n",
    "#### Een fully connected 3-layer network\n",
    "\n",
    "We gaan ons supersimpele netwerk nu uitbouwen tot een fully connected 3-layer network zoals hieronder:\n",
    "\n",
    "![Compleet netwerk](./img/network_complex.png \"Compleet netwerk\")\n",
    "\n",
    "#### Waarom meer lagen?!\n",
    "\n",
    "Het idee is dat een netwerk met meerdere lagen, complexere taken kan uitvoeren. In theorie zou de accuracy voor de MNIST dataset hiermee verhoogd moeten kunnen worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hJk5zmxzaQS"
   },
   "source": [
    "### Opdracht 2.a. Het netwerk opbouwen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We moeten een nieuw netwerk klasse gaan bouwen, noem deze `ComplexNetwork` (zie de klassedefinitie van `SimpleNetwork` eerder in dit notebook als voorbeeld)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCHkvLi74t4t"
   },
   "source": [
    "#### De eerste laag\n",
    "\n",
    "In ons eerste model hadden we een input van 784 en output van 10. Nu is de input weer 784 maar de eerste laag is een  **hidden layer** van 512 neuronen.\n",
    "\n",
    "- Voeg een `Lineair()` laag toe aan de constructor van `ComplexNetwork`. \n",
    "- Voer in de methode `ComplexNetwork.forward()` de data door deze laag en gebruik de `Sigmoid()` als activatiefunctie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tclj9vPINtNC"
   },
   "source": [
    "#### De tweede laag\n",
    "\n",
    "- Voeg een tweede `Lineair()` laag toe aan de constructor van `ComplexNetwork` met wederom 512 neuronen. \n",
    "- Voer in de methode `ComplexNetwork.forward()` de data uit de eerste laag door deze tweede laag en gebruik de `Sigmoid()` opnieuw als activatiefunctie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSDltoq3NtNC"
   },
   "source": [
    "####  De output laag\n",
    "\n",
    "De laatste laag heeft 10 elementen, namelijk de 10 klasses. \n",
    "\n",
    "- Voeg een laag van 10 neuronen toe aan het model.\n",
    "- Voer in de methode `ComplexNetwork.forward()` de data ook door deze laag en activeer met de sigmoid.\n",
    "- In plaats van de sigmoid is het beter om als laatste te activeren met softmax -- als verbetering mag je dit ook proberen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # TODO: voeg de juiste lagen toe\n",
    "    self.fc1 = nn.Linear(784, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: voer de data door de lagen\n",
    "    return x\n",
    "  \n",
    "  def reset(self):\n",
    "    # TODO: reset de lagen naar willekeurige waarden\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laten we even kijken hoe dat eruit ziet\n",
    "complex_model = ComplexNetwork()\n",
    "\n",
    "print(complex_model)\n",
    "torchinfo.summary(complex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCLXBjRwzaQW"
   },
   "source": [
    "Als het goed is, ziet de samenvatting van het model hierboven er als volgt uit:\n",
    "\n",
    "```raw\n",
    "=================================================================\n",
    "Layer (type:depth-idx)                   Param #\n",
    "=================================================================\n",
    "ComplexNetwork                           --\n",
    "├─Linear: 1-1                            401,920\n",
    "├─Linear: 1-2                            262,656\n",
    "├─Linear: 1-3                            5,130\n",
    "├─Sigmoid: 1-4                           --\n",
    "=================================================================\n",
    "Total params: 669,706\n",
    "Trainable params: 669,706\n",
    "Non-trainable params: 0\n",
    "=================================================================\n",
    "```\n",
    "\n",
    "NB. Met deze twee extra lagen is het totaal aantal te trainen parameters dus bijna een factor 100 gegroeid: 7850 naar 669.706!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZG6N2xS4t4w"
   },
   "source": [
    "#### Training configureren\n",
    "\n",
    "Gebruik dezelfde instellingen voor het configureren van de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=complex_model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LqzDTSS4t4x"
   },
   "source": [
    "#### Trainen\n",
    "\n",
    "Gebruik dezelfde code voor het trainen van het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fKh_2zyNtNJ"
   },
   "source": [
    "### Opdracht 2.b.\n",
    "\n",
    "Hoe goed heeft dit *uitgebreidere* netwerk het gedaan ten opzicht van ons 'supersimpele' netwerk? Als het goed is, al veel beter. Ga ook voor dit netwerk spelen met de epochs en batch size en kijk of je de accuracy kunt verhogen. Kijk ook weer naar de benodigde tijd: duurt het trainen langer of korter?\n",
    "\n",
    "Speel ook met het aantal neuronen in de hidden layers, wat is het effect als je bijvoorbeeld maar 10 neuronen gebruikt in plaats van 512? Voeg eventueel ook hidden layers toe.\n",
    "\n",
    "**Merk op:** vergeet niet om bij elk experiment het model te resetten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrKrEz-64t4y"
   },
   "source": [
    "Geef hieronder aan welke accuracy je hebt behaald bij welk aantal epochs en welke batch size. Geef ook de structuur van je netwerk aan, dus het aantal layers en het aantal neuronen per layer.  Als je in de buurt bent van 95% accuracy op de testset, dan kun je door naar de volgende opdracht. Als het goed is, kun je nu tot zo'n 98% komen. Als dat gelukt is, kun je verder gaan met de volgende opdracht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "_Schrijf hier je antwoord._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ugdPPfrNtNO"
   },
   "source": [
    "## Deel II. Terug naar het verleden: MNIST met _k_-Nearest Neighbours\n",
    "\n",
    "Zou het ook mogelijk zijn om cijfers te herkennen met de modellen die we geleerd hebben bij CM? Het is een classificatieprobleem dus regressie en clustering vallen af. Decision Trees zijn niet handig bij grote hoeveelheden features maar kNN kan prima over weg met veel features en in theorie zou je kNN kunnen gebruiken voor de MNIST dataset. Maar werkt het ook in de praktijk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxOG5FuHzaQY"
   },
   "source": [
    "### Opdracht 3.a. _k_-NN voor MNIST\n",
    "\n",
    "Duik het verleden in en trek _k_-NN van de plank om een classifier te maken voor de MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzegdlJ6zaQZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier    # kNN from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsiyaKBCzaQZ"
   },
   "source": [
    "Voer de volgende acties uit in de cellen hieronder:\n",
    "\n",
    "- Gebruik `X_train` en `y_train` om een kNN classifier te fitten. \n",
    "- Leg een voorspelling voor `X_test` vast in `y_pred`. \n",
    "- Vergelijk deze met `y_test` en bereken de accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07QJ0_otzaQZ",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhHN4j-NzaQZ"
   },
   "source": [
    "### Resultaten analyseren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak een _confusion matrix_ `cm` door de voorspelde klassen te vergelijken met de werkelijke klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cel hieronder visualiseert de confusion matrix `cm` voor meer inzicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yilbvHsSzaQa"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5), dpi=100)\n",
    "\n",
    "ax = sns.heatmap(pd.DataFrame(cm), annot=True, cmap='Greens', fmt='d')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "ax.set_xlabel('voorspelde waarde')\n",
    "ax.set_ylabel('echte waarde')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrWemgjPzaQa"
   },
   "source": [
    "### Opdracht 3.b. Accuracy verhogen\n",
    "\n",
    "Speel met de hyperparameters van kNN om de accuracy te verhogen.\n",
    "Wat valt je op aan de accuracy van kNN t.o.v. het neuraal netwerk? En de performance van kNN t.o.v. het neuraal netwerk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl3eL1knzaQa"
   },
   "source": [
    "Geef hieronder de gevonden resultaten aan. Geef in ieder geval aan hoeveel _neighbors_ je hebt gebruikt, wat de afstandsfunctie was en hoe groot je train en je testset waren. Maak ook een vergelijking in performance tussen het neurale netwerk en _k_-NN.\n",
    "\n",
    "Als het goed is, kun je nu tot zo'n 97% komen. Als dat gelukt is, ben je klaar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "_Schrijf hier je antwoord._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zasdy-jIzaQa"
   },
   "source": [
    "### Beperkingen van kNN\n",
    "\n",
    "kNN doet het harstikke goed voor MNIST. Maar we hebben het hier over plaatjes van 28 x 28 pixels die eigenlijk zwart wit zijn. Wat als we complexere plaatjes zouden gebruiken? Of plaatjes van 1920x1080 pixels? De performance van kNN wordt dan dramatisch en de accuracy is dan ook bedroevend...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel III. Fashion MNIST (extra)\n",
    "\n",
    "De [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist/) lijkt op MNIST, maar de plaatjes zijn iets complexer. Kledingstukken lijken qua vorm meer op elkaar en er wordt gebruik gemaakt van meerdere grijstinten. \n",
    "\n",
    "![Fashion MNIST](./img/fashion_mnist.png \"Fashion MNIST\")\n",
    "\n",
    "De accuracy van kNN duikt voor deze dataset al richting de 85%... niet best dus... en we hebben het hier nog steeds over superkleine plaatjes. Moet je na gaan wat er gebeurt bij grotere plaatjes.\n",
    "\n",
    "Enfin, als je het leuk vindt om met de Fashion MNIST dataset aan de slag te gaan, gebruik dan onderstaande code om de dataset te importeren. Voor een goede analyse doorloop je uiteraard weer dezelfde processtappen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train_data = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=ToTensor(), target_transform=None)\n",
    "fashion_test_data = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=ToTensor(), target_transform=None)\n",
    "fashion_classes = dict(enumerate(fashion_train_data.classes))\n",
    "\n",
    "fashion_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Schrijf hier je code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusies\n",
    "\n",
    "Hopelijk heb je door deze workshop een beter beeld van wat neurale netwerken zijn en hoe ze werken en hebben we jullie gemotiveerd voor S4 van AI: _Deep Learning_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel IV. Deep learning met convolutionele neurale netwerken (CNNs)\n",
    "\n",
    "### Beperkingen van neurale netwerken\n",
    "\n",
    "De gevonden resultaten zijn bemoedigend, maar neurale netwerken hebben hun beperkingen. Bekijk onderstaande geaugmenteerde varianties van de originele getallen uit de dataset:\n",
    "\n",
    "<img src=\"img/augmented_mnist.png\" />\n",
    "\n",
    "Het is telkens hetzelfde getal, maar dan:\n",
    "- Gedraaid\n",
    "- Verkleind\n",
    "- Verplaatst\n",
    "- Scheefgetrokken\n",
    "\n",
    "Laten we deze dataset eerst eens genereren!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benodigde libraries \n",
    "\n",
    "Er zijn wat nieuwe imports nodig. Eentje voor het maken van de dataset, en eentje om transformaties op data toe te kunnen passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We creëren hier een Dataset klasse AugmentedMNIST. Deze ontvangt de originele mnist dataset.\n",
    "\n",
    "class AugmentedMNIST(Dataset):\n",
    "    def __init__(self, mnist):\n",
    "        self.mnist = mnist\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mnist)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.mnist[idx]        \n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        augmentation = transforms.Compose([\n",
    "            transforms.RandomAffine(        #We transformeren random...\n",
    "                degrees=90,                 #Tot 90 graden rotatie\n",
    "                scale=(0.4, 1.0),           #Tot 40% verkleining\n",
    "                translate=(0.2, 0.2),       #Tot 20% verplaatsing\n",
    "                shear=25                    #Tot 25 graden scheeftrekken\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "        image = augmentation(image)\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = transforms.Normalize((0.5,), (0.5,))(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "augmented_train = AugmentedMNIST(dataset_train)\n",
    "augmented_test = AugmentedMNIST(dataset_test)\n",
    "\n",
    "#We herhalen de stappen van voorheen voor het prepareren van de datasets\n",
    "\n",
    "x_train = torch.zeros(size=(60000, 28, 28))\n",
    "y_train = torch.zeros(size=(60000, 1))\n",
    "\n",
    "for i, data in enumerate(augmented_train):\n",
    "    # Verwijder kleurkanaal\n",
    "    x_train[i] = data[0].reshape(28,28) \n",
    "    y_train[i] = data[1]\n",
    "    \n",
    "x_test = torch.zeros(size=(10000, 28, 28))\n",
    "y_test = torch.zeros(size=(10000, 1))\n",
    "\n",
    "for i, data in enumerate(augmented_test):\n",
    "    # Verwijder kleurkanaal\n",
    "    x_test[i] = data[0].reshape(28,28) \n",
    "    y_test[i] = data[1]\n",
    "\n",
    "X_train = x_train.reshape(60000, 784)  \n",
    "X_test = x_test.reshape(10000, 784)\n",
    "\n",
    "n_classes = 10  # Aantal klassen\n",
    "\n",
    "Y_train = one_hot(y_train.long(), n_classes).squeeze().float()\n",
    "Y_test = one_hot(y_test.long(), n_classes).squeeze().float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En we creëren, trainen en evalueren het (complexe) lineaire model.\n",
    "batch_size = 512 # Voor dit probleem werkt een batch size van 512 beter\n",
    "linear_model = ComplexNetwork()\n",
    "linear_model.to(device)\n",
    "\n",
    "# Definieer training loader\n",
    "training_set = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=linear_model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n",
    "\n",
    "print(f\"\\nStarting training with batch size {batch_size}.\")\n",
    "loss_history, accuracy_history = list(), list()\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(20):\n",
    "    loss = train(linear_model, training_loader, optimizer, loss_fn, device)\n",
    "    accuracy = evaluate(linear_model, X_test, Y_test, device=device)\n",
    "    \n",
    "    loss_history.append(float(loss))\n",
    "    accuracy_history.append(float(accuracy))\n",
    "    time_lap = time.time()\n",
    "    print(f\"Epoch {epoch}: loss = {loss:.3f}; accuracy = {accuracy:.2f}, time: {time_lap - time_start:.1f}s\")\n",
    "\n",
    "plt.plot(accuracy_history, label=f\"batch size {batch_size}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(f\"Test set accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet gaat zelf ons relatief complexe neurale netwerk de mist in bij deze dataset. Het model is te rigide en kan de grote variëteit van plaatjes in de dataset niet aan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = torch.argmax(linear_model(X_test.to(device)), dim=1)\n",
    "predicted_classes = predicted_classes.to('cpu')\n",
    "\n",
    "incorrect_indices = torch.nonzero(predicted_classes != y_test.squeeze())\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for i, correct in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='binary', interpolation='none')\n",
    "    plt.title(f\"Predicted {int(predicted_classes[correct])}\\n Class {int(y_test[correct])}\")\n",
    "    plt.axis('off')   \n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oplossing: kijken zoals mensen kijken\n",
    "\n",
    "Wanneer wij een plaatje zien, gaan wij niet naar alle pixels kijken en daarmee bepalen of een plaatje een 3 is of iets anders. Wij kijken naar bepaalde patronen, vormen en/of structuren, bijvoorbeeld de drie *pootjes* die een drie heeft of de twee *rondjes* die een acht vormen. We kijken naar scheidingen tussen objecten op een foto of zaken die op de voorgrond of achtergrond staan. Op die manier maken wij onze *voorspellingen*. En dat is precies wat convolutionele neurale netwerken doen.\n",
    "\n",
    "Voor de rest deel IV gaan we een convolutioneel netwerk toepassen op deze geaugmenteerde MNIST dataset! Heb je geen GPU ter beschikking, doe dan even samen met een student die dit wel heeft (anders duurt het te lang).\n",
    "\n",
    "**Opdracht 1 - eenvoudig convolutioneel netwerk**\n",
    "\n",
    "Vind voor alle parameters in onderstaande ConvNetwork die op 0 staan de waarden zodanig dat je het model kunt runnen zonder fouten én de prestatie hoger wordt dan 80%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(                              # We beginnen met een convolutielaag\n",
    "                in_channels=0,                      # Hoeveel inputkanalen heeft de convolutionele laag?\n",
    "                out_channels=0,                     # Met hoeveel outputkanalen kan een prestatie van minimaal 80% behaald worden?\n",
    "                kernel_size=0,                      # Met welke kernelgrootte kan een prestatie van minimaal 80% behaald worden?\n",
    "                padding=0                           # Met welke padding kan een prestatie van minimaal 80% behaald worden?\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=0, stride=0),  # Met welke kernel_size en stride kan een prestatie van minimaal 80% behaald worden?\n",
    "            \n",
    "            # We eindigen met dezelfde lineaire lagen als in ons complexe lineaire model (maar wel met ReLu ipv Sigmoid)\n",
    "            nn.Flatten(),            \n",
    "            nn.Linear(0, 512),                      # Hoe groot is de vector die we uit de MaxPool2d laag krijgen?\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/evaluatie functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in data_loader:  # Loop in batches door de loader        \n",
    "        # Data op juiste device plaatsen\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Voorspel voor gehele dataset\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # Decodeer voorspellingen\n",
    "        predicted = torch.argmax(predictions, dim=1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, epochs = 20):\n",
    "    # Definieer training loader\n",
    "    training_loader = DataLoader(augmented_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "    # Omdat nu ook het evalueren op de testset veel geheugen gaat vragen, breken we deze ook op in batches\n",
    "    testing_loader = DataLoader(augmented_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_history, accuracy_history = list(), list()\n",
    "    time_start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train(model, training_loader, optimizer, loss_fn, device)\n",
    "        accuracy = evaluate(model, testing_loader, device=device)\n",
    "        loss_history.append(float(loss))\n",
    "        accuracy_history.append(float(accuracy))\n",
    "\n",
    "        time_lap = time.time()\n",
    "        print(f\"Epoch {epoch}: loss = {loss:.3f}; accuracy = {accuracy:.2f}, time: {time_lap - time_start:.1f}s\")\n",
    "\n",
    "    plt.plot(accuracy_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Test set accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En we creëren, trainen en evalueren het convolutionele model.\n",
    "# (Zet het aantal epochs omlaag als je nog niet zeker weet of je de juiste settings hebt. Op 5 bijvoorbeeld.)\n",
    "conv_model = ConvNetwork()\n",
    "train_eval(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geleerde convoluties\n",
    "\n",
    "Zoals je ziet, presteert dit convolutionele neurale netwerk al een stuk beter dan ons lineare netwerk. Je weet ondertussen hoe neurale netwerken werken én je weet hoe convoluties werken. Tijd om deze twee concepten samen te voegen! De kernels in bovenstaande convolutionaire laag zijn niet van te voren gedefinieerd. Het mooie aan een kernel is dat dit ook gewoon een matrix met gewichten is. Net als bij de gewichten van de lineaire lagen, initieren we de gewichten van de willekeurig. Met behulp van backpropagation leert het model zelf welke convoluties geleerd moeten worden.\n",
    "\n",
    "Hieronder zie je de eerste acht kernels die zijn geleerd in deze eerste laag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = conv_model.model[0]\n",
    "kernels = conv_layer.weight.data.cpu()\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "\n",
    "vmin = kernels[:8, 0].min()\n",
    "vmax = kernels[:8, 0].max()\n",
    "\n",
    "for i in range(8):\n",
    "    ax = axes[i]\n",
    "    kernel = kernels[i, 0]\n",
    "    \n",
    "    im = ax.imshow(kernel, cmap='viridis', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f'Kernel {i}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.subplots_adjust(right=0.92)\n",
    "cbar_ax = fig.add_axes([0.94, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "plt.suptitle('Eerste 8 geleerde kernels', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 0.92, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet ziet elke kernel er anders uit. Elke kernel herkent dus andere eigenschappen van de plaatjes. Dit is het gevolg van twee dingen:\n",
    "- Random initialisatie - elke kernel begint met willekeurige, end dus unieke, waarden.\n",
    "- Backpropagation - doordat het herkennen van verschillende eigenschappen zorgt voor betere resultaten, stuurt backpropagation daar automatisch naartoe.\n",
    "\n",
    "Laten we nu eens kijken hoe het resultaat van deze convolutielaag eruit ziet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 1\n",
    "image = x_train[image_idx:image_idx+1].unsqueeze(1).to(device)  # [1, 1, 28, 28]\n",
    "\n",
    "conv_model.eval()\n",
    "with torch.no_grad():\n",
    "    conv1_out = conv_model.model[0](image)  # Conv2d\n",
    "    relu1_out = conv_model.model[1](conv1_out)  # ReLU\n",
    "    pool1_out = conv_model.model[2](relu1_out)  # MaxPool2d\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(conv1_out[0, i].cpu(), cmap='viridis')\n",
    "    plt.title(f'Conv {i}')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ziet dat de verschillende kernels andere resultaten tot gevolg hebben. De ene kernel activeert bijvoorbeeld vertical lijnen, en de andere horizontale. De resultaten van deze convoluties worden hierna door de ReLu activatiefunctie gehaald. Laten we eens kijken wat er met de plaatjes gebeurt als we deze door de ReLu-functie halen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(relu1_out[0, i].cpu(), cmap='viridis')\n",
    "    plt.title(f'Relu {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet maakt de ReLufunctie nog duidelijker wat de kernels herkennen. Alle negatieve resultaten worden weggefiltert, waardoor alleen de patronen overblijven die door de kernels gevonden zijn. De laatste stap is de maxpoollaag. Laten we de output daarvan ook eens bekijken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(pool1_out[0, i].cpu(), cmap='viridis')\n",
    "    plt.title(f'Maxpool {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plaatjes zijn kleiner, maar toch lijkt het alsof er weinig informatie is weggegooid. Sterker nog: de gevonden patronen komen nog sterker naar voren!\n",
    "\n",
    "**Opdracht 2 - Complex convolutioneel neuraal netwerk**\n",
    "\n",
    "Het is interessant om te zien dat ons eenvoudige neurale netwerk al een prestatie behaald van 80%, maaar dat kan vast beter! Laten we ons netwerk uitbreiden. Ga zelf op zoek naar een netwerk dat zowel relatief efficient als effectief is. Zorg voor een prestatie van minimaal 90%. Waar zit de balans? Heeft het toevoegen van dropout layers nut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConvNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexConvNetwork, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(                              # We beginnen met een convolutielaag\n",
    "                in_channels=0,                      # Hoeveel inputkanalen heeft de convolutionele laag?\n",
    "                out_channels=0,                     # Met hoeveel outputkanalen kan een prestatie van minimaal 80% behaald worden?\n",
    "                kernel_size=0,                      # Met welke kernelgrootte kan een prestatie van minimaal 80% behaald worden?\n",
    "                padding=0                           # Met welke padding kan een prestatie van minimaal 80% behaald worden?\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=0, stride=0),  # Met welke kernel_size en stride kan een prestatie van minimaal 80% behaald worden?\n",
    "\n",
    "            # Welke lagen moeten worden toegevoegd om minimaal 90% te behalen?\n",
    "            \n",
    "            # We eindigen met dezelfde lineaire lagen als in ons complexe lineaire model (maar wel met ReLu ipv Sigmoid)\n",
    "            nn.Flatten(),            \n",
    "            nn.Linear(0, 512),                      # Hoe groot is de vector die we uit de MaxPool2d laag krijgen?\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En we creëren, trainen en evalueren het (complexe) convolutionele model.\n",
    "# (Zet het aantal epochs omlaag als je nog niet zeker weet of je de juiste settings hebt. Op 5 bijvoorbeeld.)\n",
    "\n",
    "complex_conv_model = ComplexConvNetwork()\n",
    "train_eval(complex_conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "\n",
    "- Khan, Muhammad Asad Iqbal. (2023, May 3). _Activation Functions in PyTorch._ https://machinelearningmastery.com/activation-functions-in-pytorch/\n",
    "\n",
    "- Snelgrove, Xavier. (2016, January 27). _Building a simple neural-network with Keras._ https://github.com/wxs/keras-mnist-tutorial\n",
    "\n",
    "- Chejara, Amit Subhash. (2025, Apr 10). _How I Hit 99.26% Accuracy on MNIST with a CNN in PyTorch._ https://medium.com/data-science-collective/implementing-cnn-in-pytorch-testing-on-mnist-99-26-test-accuracy-5c63876c6ac8\n",
    "\n",
    "- Subramanian, S., Juarez, S., Breviu, C., Soshnikov, D., & Bornstein, A. (2025, Jul 7). _PyTorch: Learn the Basics._ https://docs.pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "Les 1. Workshop neurale netwerken MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-s4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
